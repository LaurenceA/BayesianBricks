TODOs:
  when you initialize an MCMC kernel:
    consider inter-object dependencies:
      see whether there's a lower-level subtree that contains all refs to the rvs
    consider inter-dimension dependencies: dimensions independent if:
      Independent prior over all sampled rvs
      Data, and all RV's have the same shape along those dimensions.
      Only pointwise transformations between all RV's and data.

      each model has a field, dep_dims, describing the dimensions it makes dependent.
      start at data, go backwards through the tree collecting dep_dims:
        if there's none of our rv's on a branch, return the empty list
        if there's a non-sampled BrRV, stop (and don't collect dims)
      any remaining dims should be independent.  check:
        data and rv's have same shape along those dimensions

  check whether everything is refreshed as it should be!

  Refactor Model/Deps/RVs
  Joint distribution as a container for multiple conditioned variables.
  
  Test:
    independent accept/reject steps
    BrRV
  Metropolis:
    step-size adaptation
    avoid RV log-probability ratios using something like Langevin/single-step HMC
  VI:
    low-rank mass matrix 
  Docs
  examples:
    confidence
    neural firing
    calcium? (Exponential + threshold).
    flips in 
    
    
Gamma priors:
  scale: 
    has Gamma conjugate prior
    equals var/mean, and can thus be viewed as a dispersion parameter.
  mean: 
    resonable to use a Gamma prior
  shape:
    obtain using mean / scale

testing


lapses:
  slow, multiplicative drift

noisy accumulator:
  convolution for speed

diffusion to bound (explicit):
  discretise time
  binary variables (stop/don't stop) for each time-point
    these binary variables are observed (give the reaction time)
    use a fairly sharp sigmoid for the top and bottom
    initialize as a straight line from start point to decision

diffusion to bound (integrated):

kalman filter:
  

discrete confidence (e.g. 1-6)
  parameterise thresholds as:
    discrete distribution over 1-6 (but not equal to the marginal dist. over confidences)
    assume a distriubtion (e.g. Gaussian) over confidences (not equal to the marginal dist)
    back solve for the thresholds 



Data:
  Noisy accumulator:
    Valentin Wyart/Alex Pouget
  Diffusion to bound:
    Roozbeh? Angela Yu?
  Kalman Filter:
    Angela Yu?  
  Confidence:
    Bahador?
